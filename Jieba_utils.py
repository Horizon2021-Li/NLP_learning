import jieba
content = "无线电法国别研究"
# 精确模式分词:
jieba.cut(content, cut_all=False)  # cut_all默认为False

# 将返回一个生成器对象
# <generator object Tokenizer.cut at 0x7f065c19e318>

# 若需直接返回列表内容, 使用jieba.lcut即可
jieba.lcut(content, cut_all=False)
# ['无线电', '法国', '别', '研究']

#---------------------------------------------------------------------------------------------#
# 全模式分词：
# 若需直接返回列表内容, 使用jieba.lcut即可
jieba.lcut(content, cut_all=True)
#['无线', '无线电', '法国', '国别', '研究']

#---------------------------------------------------------------------------------------------#
# 搜索引擎模式分词：
# 在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。
# 若需直接返回列表内容, 使用jieba.lcut_for_search即可
jieba.lcut_for_search(content)

#---------------------------------------------------------------------------------------------#
# 使用用户自定义词典:
# 词典格式: 每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。
jieba.lcut("八一双鹿更名为八一南昌篮球队！")
# 没有使用用户自定义词典前的结果:
# ['八', '一双', '鹿', '更名', '为', '八一', '南昌', '篮球队', '！']

jieba.load_userdict("./userdict.txt")
jieba.lcut("八一双鹿更名为八一南昌篮球队！")
# 使用了用户自定义词典后的结果:
#['八一双鹿', '更名', '为', '八一', '南昌', '篮球队', '！']